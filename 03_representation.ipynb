{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "import scipy as sp\n",
    "from scipy import sparse\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "import sklearn\n",
    "import sklearn.mixture\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "import time\n",
    "import pickle\n",
    "import memory_profiler\n",
    "%load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We tried different representations and compared their kNN accuracy scores.\n",
    "\n",
    "Representations:\n",
    "- Word counts\n",
    "- Log-transformed counts\n",
    "- Term frequencies (TF)\n",
    "- scRNA-seq approach\n",
    "- Schmidt (2018)\n",
    "- TF-IDF without log-scaling\n",
    "- TF-IDF with log-scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data\n",
    "clean_df=pd.read_pickle(\"variables/clean_df\")\n",
    "\n",
    "# colors\n",
    "automatic_colors=np.load(\"variables/automatic_colors.npy\", allow_pickle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = clean_df['AbstractText'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Counts (WC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 151375.08 MiB, increment: 84294.96 MiB\n",
      "CPU times: user 29min 24s, sys: 1min 38s, total: 31min 2s\n",
      "Wall time: 31min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%memit\n",
    "\n",
    "# CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "word_counts = vectorizer.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save results\n",
    "sp.sparse.save_npz(\"variables/word_counts\", word_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts = sp.sparse.load_npz(\"variables/word_counts.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts = sp.sparse.load_npz(\"/gpfs01/berens/user/rgonzalesmarquez/ICLR_workshop/new_variables/word_counts.npz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log-transformed counts\n",
    "log(1+WC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_1_WC=np.log1p(word_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11min, sys: 19.1 s, total: 11min 19s\n",
      "Wall time: 11min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# save results\n",
    "sp.sparse.save_npz(\"variables/log_1_WC\", log_1_WC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_1_WC = sp.sparse.load_npz(\"variables/log_1_WC.npz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Term frequencies (TF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "term_frequencies=normalize(word_counts, axis=1, norm='l1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9min 52s, sys: 23 s, total: 10min 15s\n",
      "Wall time: 10min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# save results\n",
    "sp.sparse.save_npz(\"variables/term_frequencies\", term_frequencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "term_frequencies = sp.sparse.load_npz(\"variables/term_frequencies.npz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### scRNA-seq approach\n",
    "log(1+ TF*(average doc_len=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 17 ms, sys: 43.1 ms, total: 60.1 ms\n",
      "Wall time: 57.8 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "doc_len=np.diff(term_frequencies.indptr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average number of words per abstract:  105.91494290058827\n"
     ]
    }
   ],
   "source": [
    "print('Average number of words per abstract: ', np.mean(doc_len))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We approximate the average number of words per abstract to 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 34.2 s, sys: 9.88 s, total: 44.1 s\n",
      "Wall time: 44.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# doc_len=np.diff(term_frequencies.indptr)\n",
    "TF_doc_len_term=csr_matrix.multiply(term_frequencies, 100) \n",
    "log_1_TF_doc_len = np.log1p(TF_doc_len_term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save results\n",
    "sp.sparse.save_npz(\"variables/log_1_TF_doc_len\", log_1_TF_doc_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_1_TF_doc_len = sp.sparse.load_npz(\"variables/log_1_TF_doc_len.npz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Schmidt (2018) (modified) \n",
    "max([0, log(TF*100)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#final\n",
    "TF_100=csr_matrix.multiply(term_frequencies, 100) # if I multiply it by a scalar the format is still csr matrix\n",
    "log_term=csr_matrix((np.log(TF_100.data), TF_100.indices, TF_100.indptr), shape=TF_100.shape)\n",
    "schmidts_feature=csr_matrix.maximum(log_term,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save results\n",
    "sp.sparse.save_npz(\"variables/schmidts_feature\", schmidts_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "schmidts_feature = sp.sparse.load_npz(\"variables/schmidts_feature.npz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF without log-scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "%%memit\n",
    "\n",
    "vectorizer = TfidfVectorizer(sublinear_tf=False)\n",
    "tfidf_sublinear_tf_False = vectorizer.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save results\n",
    "sp.sparse.save_npz(\"variables/tfidf_sublinear_tf_False\", tfidf_sublinear_tf_False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_sublinear_tf_False = sp.sparse.load_npz(\"variables/tfidf_sublinear_tf_False.npz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF with log-scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "%%memit\n",
    "\n",
    "vectorizer = TfidfVectorizer(sublinear_tf=True)\n",
    "tfidf_features = vectorizer.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save results\n",
    "sp.sparse.save_npz(\"variables/tfidf_features\", tfidf_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_features = sp.sparse.load_npz(\"variables/tfidf_features.npz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# kNN accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_knn_score_split(Zs, colors, k=10, subset_size=500, rs=42):\n",
    "    \"\"\"\n",
    "    Gets the knn accuracy of the points with a color different than grey.\n",
    "    \"\"\"\n",
    "    \n",
    "    knn_scores=[]\n",
    "    \n",
    "    for i, Xrp in enumerate(Zs):\n",
    "        n = np.sum(colors!='lightgrey')\n",
    "        np.random.seed(rs)\n",
    "        test = np.random.choice(n, size=subset_size, replace=False)\n",
    "        train = np.setdiff1d(np.arange(n), test)\n",
    "\n",
    "        neigh = KNeighborsClassifier(n_neighbors=10, algorithm='brute')\n",
    "        neigh.fit(Xrp[colors!='lightgrey'][train], colors[colors!='lightgrey'][train])\n",
    "        acc = np.mean(neigh.predict(Xrp[colors!='lightgrey'][test]) == colors[colors!='lightgrey'][test])\n",
    "        knn_scores.append(acc)\n",
    "\n",
    "    return knn_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Counts (WC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 191280.11 MiB, increment: 21137.88 MiB\n",
      "CPU times: user 13min 2s, sys: 1min 31s, total: 14min 33s\n",
      "Wall time: 14min 35s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%memit\n",
    "knn_accuracy_WC= get_knn_score_split([word_counts] , automatic_colors, subset_size=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"variables/knn_accuracy_WC\",knn_accuracy_WC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_accuracy_WC=np.load(\"variables/knn_accuracy_WC.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### log(1+WC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 63677.96 MiB, increment: 16930.64 MiB\n",
      "CPU times: user 12min 6s, sys: 55.6 s, total: 13min 2s\n",
      "Wall time: 13min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%memit\n",
    "knn_accuracy_log_1_WC= get_knn_score_split([log_1_WC] , automatic_colors, subset_size=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"variables/knn_accuracy_log_1_WC\",knn_accuracy_log_1_WC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_accuracy_log_1_WC=np.load(\"variables/knn_accuracy_log_1_WC.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "%%memit\n",
    "knn_accuracy_TF= get_knn_score_split([term_frequencies] , automatic_colors, subset_size=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"variables/knn_accuracy_TF\",knn_accuracy_TF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_accuracy_TF=np.load(\"variables/knn_accuracy_TF.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### log(1+ TF*(average doc_len=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 111066.86 MiB, increment: 17393.99 MiB\n",
      "CPU times: user 12min 26s, sys: 1min 9s, total: 13min 36s\n",
      "Wall time: 13min 38s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%memit\n",
    "knn_accuracy_log_1_TF_doc_len= get_knn_score_split([log_1_TF_doc_len] , automatic_colors, subset_size=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"variables/knn_accuracy_log_1_TF_doc_len\",knn_accuracy_log_1_TF_doc_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_accuracy_log_1_TF_doc_len=np.load(\"variables/knn_accuracy_log_1_TF_doc_len.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Schmidt: max([0, log(TF*100)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "%%memit\n",
    "knn_accuracy_schmidts_feature= get_knn_score_split([schmidts_feature] , automatic_colors, subset_size=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"variables/knn_accuracy_schmidts_feature\",knn_accuracy_schmidts_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_accuracy_schmidts_feature=np.load(\"variables/knn_accuracy_schmidts_feature.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tf-idf without sublinear scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 38419.64 MiB, increment: 14842.84 MiB\n",
      "CPU times: user 13min 49s, sys: 57 s, total: 14min 46s\n",
      "Wall time: 14min 48s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%memit\n",
    "knn_accuracy_tfidf_sublinear_tf_False= get_knn_score_split([tfidf_sublinear_tf_False] , automatic_colors, subset_size=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"variables/knn_accuracy_tfidf_sublinear_tf_False\",knn_accuracy_tfidf_sublinear_tf_False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_accuracy_tfidf_sublinear_tf_False=np.load(\"variables/knn_accuracy_tfidf_sublinear_tf_False.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tf-idf with sublinear scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 38419.64 MiB, increment: 14842.84 MiB\n",
      "CPU times: user 13min 49s, sys: 57 s, total: 14min 46s\n",
      "Wall time: 14min 48s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%memit\n",
    "knn_accuracy_tfidf= get_knn_score_split([tfidf_features] , automatic_colors, subset_size=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"variables/knn_accuracy_tfidf\",knn_accuracy_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_accuracy_tfidf=np.load(\"variables/knn_accuracy_tfidf.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word counts:  [0.494]\n",
      "log(1+ WC):  [0.538]\n",
      "TF:  [0.54]\n",
      "log(1 + TF*100):  [0.616]\n",
      "max([0, log(TF*100)]):  [0.428]\n",
      "tf-idf (without log):  [0.628]\n",
      "tf-idf (with log):  [0.712]\n"
     ]
    }
   ],
   "source": [
    "print('Word counts: ', knn_accuracy_WC)\n",
    "print('log(1+ WC): ', knn_accuracy_log_1_WC)\n",
    "print('TF: ', knn_accuracy_TF)\n",
    "print('log(1 + TF*100): ', knn_accuracy_log_1_TF_doc_len) \n",
    "print('max([0, log(TF*100)]): ', knn_accuracy_schmidts_feature)\n",
    "print('tf-idf (without log): ', knn_accuracy_tfidf_sublinear_tf_False)\n",
    "print('tf-idf (with log): ', knn_accuracy_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.494, 0.538, 0.54 , 0.616, 0.428, 0.628, 0.712])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessings = ['Word counts', 'Log-transformed counts', 'Term frequencies (TF)', 'scRNA-seq approach',\n",
    "                  'Schmidt (2018)', 'TF-IDF without log scaling', 'TF-IDF with log scaling']\n",
    "\n",
    "knn_accuracies= np.hstack((knn_accuracy_WC, knn_accuracy_log_1_WC, knn_accuracy_TF, \n",
    "                    knn_accuracy_log_1_TF_doc_len, knn_accuracy_schmidts_feature, knn_accuracy_tfidf_sublinear_tf_False, knn_accuracy_tfidf))\n",
    "knn_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kNN accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Word counts</th>\n",
       "      <td>0.494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Log-transformed counts</th>\n",
       "      <td>0.538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Term frequencies (TF)</th>\n",
       "      <td>0.540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scRNA-seq approach</th>\n",
       "      <td>0.616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Schmidt (2018)</th>\n",
       "      <td>0.428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TF-IDF without log scaling</th>\n",
       "      <td>0.628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TF-IDF with log scaling</th>\n",
       "      <td>0.712</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            kNN accuracy\n",
       "Word counts                        0.494\n",
       "Log-transformed counts             0.538\n",
       "Term frequencies (TF)              0.540\n",
       "scRNA-seq approach                 0.616\n",
       "Schmidt (2018)                     0.428\n",
       "TF-IDF without log scaling         0.628\n",
       "TF-IDF with log scaling            0.712"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(knn_accuracies, preprocessings, columns= ['kNN accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
